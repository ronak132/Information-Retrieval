{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My goal is to build a classifier to determine if a Yelp review is \"food-relevant\" or not.\n",
    "\n",
    "## Dataset: Yelp review data\n",
    "\n",
    "First, you will need to download the training_data.json file from the Resources tab on Piazza, a collection of 40,000 json-encoded Yelp reviews we sampled from the [Yelp Dataset Challenge](https://www.yelp.com/dataset_challenge).\n",
    "\n",
    "You'll see that each line corresponds to a review on a particular business. The label (class) information of each review is in the \"label\" field. It is **either \"Food-relevant\" or \"Food-irrelevant\"**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.1: Parsing Yelp\n",
    "\n",
    "For this first part, we will build a parser for extracting tokens from the **review text** only. First, you should tokenize each review using **whitespaces and punctuations as delimiters**. Do not remove stopwords. You should apply casefolding (lower case everything) and use the [nltk Porter stemmer](http://www.nltk.org/api/nltk.stem.html#module-nltk.stem.porter) ... you may need to install nltk if you don't have it already. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique tokens?\n",
    "\n",
    "Once you have your parser working, you should report here the size of your feature space. That is, how many unique tokens do you find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started\n",
      "36555\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import string\n",
    "import operator\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "file = 'F:/SEM-2/IR/HW_1/train.json'\n",
    "st = PorterStemmer()\n",
    "words = []\n",
    "lines = []\n",
    "labels = []\n",
    "\n",
    "print'started'\n",
    "with open(file) as f:\n",
    "    for line in f:\n",
    "        #print(line)\n",
    "        json_data = json.loads(line.lower())\n",
    "        text = json_data['text']\n",
    "        lines.append(text)\n",
    "        label = json_data['label']\n",
    "        #print(label)\n",
    "        labels.append(label)\n",
    "        #print(json_data)\n",
    "        list = re.findall('\\w+', text)\n",
    "        #print list\n",
    "        #words.append(list)\n",
    "        for temp in list:\n",
    "            #print temp, st.stem(temp)\n",
    "            words.append(st.stem(temp))\n",
    "#print words\n",
    "frequency = {}\n",
    "\n",
    "for word in words:\n",
    "    count = frequency.get(word,0)\n",
    "    frequency[word] = count + 1\n",
    "     \n",
    "frequency_list = frequency.keys()\n",
    "print len(frequency_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Most Popular Words\n",
    "\n",
    "Great, now we can tokenize the documents. Let's make a list of the most popular words in our reviews. For this step, you should maintain a count of how many times each word occurs. Then you should print out the top-20 words in your reviews.\n",
    "\n",
    "Your output should look like this:\n",
    "\n",
    "Rank Token Count\n",
    "\n",
    "1 awesome 78\n",
    "\n",
    "... ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 246309\n",
      "i 168931\n",
      "and 168589\n",
      "a 134904\n",
      "to 128139\n",
      "it 78867\n",
      "of 76237\n",
      "wa 74020\n",
      "is 63496\n",
      "for 60867\n",
      "in 60523\n",
      "that 50804\n",
      "my 50565\n",
      "you 45881\n",
      "they 43635\n",
      "thi 39940\n",
      "with 39340\n",
      "have 39082\n",
      "but 37967\n",
      "on 35388\n"
     ]
    }
   ],
   "source": [
    "freq_sorted = sorted(frequency, key=frequency.get, reverse=True)\n",
    "for r in freq_sorted[:20]:\n",
    "    print r, frequency[r]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zipf's Law\n",
    "\n",
    "Recall in class our discussion of Zipf's law. Let's see if this law applies to our Yelp reviews. You should use matplotlib to plot the log-base10 term counts on the y-axis versus the log-base10 rank on the x-axis. Your aim is to create a figure like the one in Figure 5.2 of the textbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sss\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "print 'sss'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you observe? Is this consistent with Zipf's law?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.2: Feature Represenation\n",
    "\n",
    "In this part you will build feature vectors for each review. This will be input to our ML classifiers. You should call your parser from earlier, using all the same assumptions (e.g., casefolding, stemming). Each feature value should be the term count for that review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print 'start'\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(lines)\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.3: Classifiers\n",
    "\n",
    "In this part you will evaluate a bunch of classifiers -- kNN, Decision tree, Naive Bayes, and SVM -- on the feature vectors generated in the previous task in two different settings. **You do not need to implement any classifier from scratch. You may use scikit-learn's built-in capabilities.**\n",
    "\n",
    "### Setting 1: Splitting data into train-test \n",
    "\n",
    "In the first setting, you should treat the first 70% of your data as training. The remaining 30% should be for testing. \n",
    "\n",
    "### Setting 2: Using 5 fold cross-validation\n",
    "\n",
    "In the second setting, use 5-folk cross-validation. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split\n",
      "svm\n",
      "knn\n",
      "tree\n",
      "nb\n",
      "accuracy with splitting data------------------------------\n",
      "svm 0.933083333333\n",
      "knn 0.706083333333\n",
      "decision tree 0.88375\n",
      "naive bayes 0.948083333333\n",
      "precision and recall is only meaningful if they are calculated on the test data\n",
      "so they are calculated on test data and for svm classifier\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   relevant       0.94      0.93      0.93      5999\n",
      " irrelevant       0.93      0.94      0.93      6001\n",
      "\n",
      "avg / total       0.93      0.93      0.93     12000\n",
      "\n",
      "('TRAIN:', array([ 5451,  5452,  5453, ..., 39997, 39998, 39999]), 'TEST:', array([    0,     1,     2, ..., 13245, 13246, 13247]))\n",
      "('TRAIN:', array([    0,     1,     2, ..., 39997, 39998, 39999]), 'TEST:', array([ 5451,  5452,  5453, ..., 27312, 27313, 27314]))\n",
      "('TRAIN:', array([    0,     1,     2, ..., 39997, 39998, 39999]), 'TEST:', array([11513, 11514, 11515, ..., 31997, 31998, 31999]))\n",
      "('TRAIN:', array([    0,     1,     2, ..., 39997, 39998, 39999]), 'TEST:', array([17199, 17200, 17201, ..., 35997, 35998, 35999]))\n",
      "('TRAIN:', array([    0,     1,     2, ..., 35997, 35998, 35999]), 'TEST:', array([22902, 22903, 22904, ..., 39997, 39998, 39999]))\n",
      "accuracy with 5 fold cross validation------------------------------\n",
      "svm 0.925125\n",
      "knn 0.703875\n",
      "tree 0.87525\n",
      "naive bayes 0.956125\n",
      "precision and recall is only meaningful if they are calculated on the test data\n",
      "so they are calculated on test data and for svm classifier\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   relevant       0.92      0.94      0.93      4000\n",
      " irrelevant       0.93      0.92      0.92      4000\n",
      "\n",
      "avg / total       0.93      0.93      0.93      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "print 'split'\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, np.transpose(labels), test_size=0.3, random_state=42)\n",
    "\n",
    "print 'svm'\n",
    "svm_clf = svm.SVC(kernel ='linear', C = 1.0)\n",
    "svm_clf.fit(X_train,y_train)\n",
    "svm_pred = svm_clf.predict(X_test)\n",
    "\n",
    "print 'knn'\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "knn_pred = knn_clf.predict(X_test)\n",
    "\n",
    "print 'tree'\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "tree_clf.fit(X_train, y_train)\n",
    "tree_pred = tree_clf.predict(X_test)\n",
    "\n",
    "print 'nb'\n",
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(X_train, y_train)\n",
    "nb_pred = nb_clf.predict(X_test)\n",
    "\n",
    "print 'accuracy with splitting data------------------------------'\n",
    "print 'svm',accuracy_score(y_test, svm_pred)\n",
    "print 'knn',accuracy_score(y_test, knn_pred)\n",
    "print 'decision tree',accuracy_score(y_test, tree_pred)\n",
    "print 'naive bayes',accuracy_score(y_test, nb_pred)\n",
    "\n",
    "print 'precision and recall is only meaningful if they are calculated on the test data'\n",
    "print 'so they are calculated on test data and for svm classifier'\n",
    "\n",
    "target_names = ['relevant', 'irrelevant']\n",
    "print(classification_report(y_test, svm_pred, target_names=target_names))\n",
    "\n",
    "y = np.transpose(labels)\n",
    "skf = StratifiedKFold(y, n_folds=5)\n",
    "for train_index, test_index in skf:\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    XK_train, XK_test = X[train_index], X[test_index]\n",
    "    yK_train, yK_test = y[train_index], y[test_index]\n",
    "\n",
    "svmK_clf = svm.SVC(kernel ='linear', C = 1.0)\n",
    "svmK_clf.fit(XK_train,yK_train)\n",
    "svmK_pred = svmK_clf.predict(XK_test)\n",
    "\n",
    "knnK_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "knnK_clf.fit(XK_train, yK_train)\n",
    "knnK_pred = knnK_clf.predict(XK_test)\n",
    "\n",
    "treeK_clf = DecisionTreeClassifier()\n",
    "treeK_clf.fit(XK_train, yK_train)\n",
    "treeK_pred = treeK_clf.predict(XK_test)\n",
    "\n",
    "nbK_clf = MultinomialNB()\n",
    "nbK_clf.fit(XK_train, yK_train)\n",
    "nbK_pred = nbK_clf.predict(XK_test)\n",
    "\n",
    "print 'accuracy with 5 fold cross validation------------------------------'\n",
    "print 'svm',accuracy_score(yK_test, svmK_pred)\n",
    "print 'knn',accuracy_score(yK_test, knnK_pred)\n",
    "print 'tree',accuracy_score(yK_test, treeK_pred)\n",
    "print 'naive bayes',accuracy_score(yK_test, nbK_pred)\n",
    "\n",
    "print 'precision and recall is only meaningful if they are calculated on the test data'\n",
    "print 'so they are calculated on test data and for svm classifier'\n",
    "\n",
    "target_names = ['relevant', 'irrelevant']\n",
    "print(classification_report(yK_test, svmK_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.5: Improving the classifier\n",
    "\n",
    "I think we can do better! In this part, your job is to create new features that you can think can help improve your classifier. You may choose to use new weightings for your words, new derived features (e.g., count of 3-letter words), or whatever you like. You may also add in the extra features in the json: funny, useful, cool. You will need to experiment with different approaches ... once you finalize on your best approach, include the features here with a description (that is, tell us what the feature means). Then give us your classifier results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we can use TFIDF\n",
      "start\n",
      "done\n",
      "split\n",
      "svm\n",
      "knn\n",
      "tree\n",
      "NB\n",
      "accuracy with splitting data------------------------------\n",
      "svm 0.958416666667\n",
      "knn 0.512166666667\n",
      "decision tree 0.876416666667\n",
      "naive bayes 0.950083333333\n",
      "precision and recall is only meaningful if they are calculated on the test data\n",
      "so they are calculated on test data and for svm classifier\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   relevant       0.95      0.96      0.96      5999\n",
      " irrelevant       0.96      0.95      0.96      6001\n",
      "\n",
      "avg / total       0.96      0.96      0.96     12000\n",
      "\n",
      "accuracy with 5 fold cross validation------------------------------\n",
      "svm 0.954625\n",
      "knn 0.869\n",
      "tree 0.882\n",
      "naive bayes 0.958\n",
      "precision and recall is only meaningful if they are calculated on the test data\n",
      "so they are calculated on test data and for svm classifier\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   relevant       0.94      0.97      0.96      4000\n",
      " irrelevant       0.97      0.94      0.95      4000\n",
      "\n",
      "avg / total       0.96      0.95      0.95      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# your code here ... add as many cells as you need for features, results, and discussion.\n",
    "print \"we can use TFIDF\"\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "print 'start'\n",
    "Tvectorizer = TfidfVectorizer()\n",
    "XT = Tvectorizer.fit_transform(lines)\n",
    "print 'done'\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "print 'split'\n",
    "\n",
    "XT_train, XT_test, yT_train, yT_test = train_test_split(XT, np.transpose(labels), test_size=0.3, random_state=42)\n",
    "\n",
    "print 'svm'\n",
    "svm_clf = svm.SVC(kernel ='linear', C = 1.0)\n",
    "svm_clf.fit(XT_train,yT_train)\n",
    "svm_pred = svm_clf.predict(XT_test)\n",
    "\n",
    "print 'knn'\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_clf.fit(XT_train, yT_train)\n",
    "knn_pred = knn_clf.predict(XT_test)\n",
    "\n",
    "print 'tree'\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "tree_clf.fit(XT_train, yT_train)\n",
    "tree_pred = tree_clf.predict(XT_test)\n",
    "\n",
    "print 'NB'\n",
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(XT_train, yT_train)\n",
    "nb_pred = nb_clf.predict(XT_test)\n",
    "\n",
    "print 'accuracy with splitting data------------------------------'\n",
    "print 'svm',accuracy_score(yT_test, svm_pred)\n",
    "print 'knn',accuracy_score(yT_test, knn_pred)\n",
    "print 'decision tree',accuracy_score(yT_test, tree_pred)\n",
    "print 'naive bayes',accuracy_score(yT_test, nb_pred)\n",
    "\n",
    "print 'precision and recall is only meaningful if they are calculated on the test data'\n",
    "print 'so they are calculated on test data and for svm classifier'\n",
    "\n",
    "target_names = ['relevant', 'irrelevant']\n",
    "print(classification_report(y_test, svm_pred, target_names=target_names))\n",
    "\n",
    "y = np.transpose(labels)\n",
    "skf = StratifiedKFold(y, n_folds=5)\n",
    "for train_index, test_index in skf:\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    XK_train, XK_test = XT[train_index], XT[test_index]\n",
    "    yK_train, yK_test = y[train_index], y[test_index]\n",
    "\n",
    "svmK_clf = svm.SVC(kernel ='linear', C = 1.0)\n",
    "svmK_clf.fit(XK_train,yK_train)\n",
    "svmK_pred = svmK_clf.predict(XK_test)\n",
    "\n",
    "knnK_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "knnK_clf.fit(XK_train, yK_train)\n",
    "knnK_pred = knnK_clf.predict(XK_test)\n",
    "\n",
    "treeK_clf = DecisionTreeClassifier()\n",
    "treeK_clf.fit(XK_train, yK_train)\n",
    "treeK_pred = treeK_clf.predict(XK_test)\n",
    "\n",
    "nbK_clf = MultinomialNB()\n",
    "nbK_clf.fit(XK_train, yK_train)\n",
    "nbK_pred = nbK_clf.predict(XK_test)\n",
    "\n",
    "print 'accuracy with 5 fold cross validation------------------------------'\n",
    "print 'svm',accuracy_score(yK_test, svmK_pred)\n",
    "print 'knn',accuracy_score(yK_test, knnK_pred)\n",
    "print 'tree',accuracy_score(yK_test, treeK_pred)\n",
    "print 'naive bayes',accuracy_score(yK_test, nbK_pred)\n",
    "\n",
    "print 'precision and recall is only meaningful if they are calculated on the test data'\n",
    "print 'so they are calculated on test data and for svm classifier'\n",
    "\n",
    "target_names = ['relevant', 'irrelevant']\n",
    "print(classification_report(yK_test, svmK_pred, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
