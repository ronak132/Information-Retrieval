{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link Analysis -- HITS + SEO\n",
    "\n",
    "\n",
    "*Goals* Explore real-world challenges of building a graph (in this case, from tweets), implement and test HITS algortihm over this graph, and investigate factors that impact a page's rank on Google and Bing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HITS \n",
    "\n",
    "## A re-Tweet Graph\n",
    "\n",
    "In this assignment, we're going to adapt the classic HITS approach to allow us to find not the most authoritative web pages, but rather to find significant Twitter users. So, instead of viewing the world as web pages with hyperlinks (where pages = nodes, hyperlinks = edges), we're going to construct a graph of Twitter users and their retweets of other Twitter users (so user = node, retweet of another user = edge). Over this Twitter-user graph, we can apply the HITS approach to order the users by their hub-ness and their authority-ness.\n",
    "\n",
    "Here is a toy example. Suppose you are given the following four retweets:\n",
    "\n",
    "* **userID**: diane, **text**: \"RT \", **sourceID**: bob\n",
    "* **userID**: charlie, **text**: \"RT Welcome\", **sourceID**: alice\n",
    "* **userID**: bob, **text**: \"RT Hi \", **sourceID**: diane\n",
    "* **userID**: alice, **text**: \"RT Howdy!\", **sourceID**: parisa\n",
    "\n",
    "There are four short tweets retweeted by four users. The retweet between users form a directed graph with five nodes and four edges. E.g., the \"diane\" node has a directed edge to the \"bob\" node.\n",
    "\n",
    "You should build a graph by parsing the tweets in the file we provide called *HITS.json*.\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "* You may see some weird characters in the content of tweets, just ignore them. \n",
    "* The edges are weighted and directed. If Bob retweets Alice's tweets 10 times, there is an edge from Bob to Alice with weight 10, but there is not an edge from Alice to Bob.\n",
    "* If a user retweets herself, ignore it.\n",
    "* Correctly parsing screen_name in a tweet is error-prone. Use the id of the user (this is the user who is re-tweeting) and the id of the user in the retweeted_status field (this is the user who is being re-tweeted; that is, this user created the original tweet).\n",
    "* Later you will need to implement the HITS algorithm on the graph you build here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started\n",
      "number of unique users =  1003\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import dot, array\n",
    "import scipy as sp\n",
    "import json\n",
    "import collections\n",
    "from scipy import sparse\n",
    "import networkx as nx\n",
    "file = 'F:/SEM-2/IR/HW_2/HITS.json'\n",
    "d = collections.defaultdict(dict)\n",
    "names = collections.defaultdict(dict)\n",
    "user_dict = dict()\n",
    "result = {}\n",
    "words = []\n",
    "lines = []\n",
    "labels = []\n",
    "\n",
    "count = 0\n",
    "print'started'\n",
    "with open(file) as f:\n",
    "    for line in f:\n",
    "        json_data = json.loads(line.lower())\n",
    "        user = json_data['user']['id']\n",
    "        source = json_data['retweeted_status']['user']['id']\n",
    "        if not user in names.keys():\n",
    "            names[user] = count\n",
    "            count+=1\n",
    "        if not source in names.keys():\n",
    "            names[source] = count\n",
    "            count+=1\n",
    "        #result.setdefault(user, []).append(source)\n",
    "        if user in d.keys():\n",
    "            if source in d[user].keys():\n",
    "                d[user][source]+=1;\n",
    "            else:\n",
    "                d[user][source] = 1;\n",
    "        else:\n",
    "            d[user]={}\n",
    "            d[user][source] = 1;\n",
    "#print len(names)\n",
    "\n",
    "#for key in d.keys():\n",
    "    #for key1 in d[key].keys():\n",
    "        #print key,\"--\",key1, \"--\", d[key][key1]\n",
    "        \n",
    "#for name in names.keys():\n",
    "    #print name,\"--\",names[name]    \n",
    "new_graph = nx.DiGraph()\n",
    "\n",
    "for user in names.keys():\n",
    "    for frm in d[user].keys():\n",
    "        new_graph.add_edge(names[user], names[frm],weight=d[user][frm])\n",
    "adjacency_matrix = nx.adjacency_matrix(new_graph)\n",
    "\n",
    "matrix = sparse.csr_matrix(adjacency_matrix)\n",
    "#print matrix\n",
    "print \"number of unique users = \",(len(names))\n",
    "\n",
    "\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HITS Implementation\n",
    "\n",
    "This program will return the top 10 users with highest hub and authority scores. \n",
    "\n",
    "Hub Scores\n",
    "\n",
    "* user1 - score1\n",
    "* user2 - score2\n",
    "* ...\n",
    "* user10 - score10\n",
    "\n",
    "Authority Scores\n",
    "\n",
    "* user1 - score1\n",
    "* user2 - score2\n",
    "* ...\n",
    "* user10 - score10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### after 100  iterations ###############\n",
      "----------------hubs-------------------------\n",
      "3068706044: 1.0\n",
      "3093940760: 0.475287782598\n",
      "2194518394: 0.417051522555\n",
      "2862783698: 0.325115722927\n",
      "3092183276: 0.27365327709\n",
      "3029724797: 0.267990465997\n",
      "2990704188: 0.237086961228\n",
      "3001500121: 0.232422074305\n",
      "3086921438: 0.207265056826\n",
      "3042686360: 0.201026535312\n",
      "3092935664: 0.19709589533\n",
      "3021183212: 0.194054207202\n",
      "3118683560: 0.182011802877\n",
      "3084868798: 0.163743008103\n",
      "2935948649: 0.161077825823\n",
      "3089225044: 0.161014033197\n",
      "3064218544: 0.142877265727\n",
      "3091417449: 0.134306033739\n",
      "3059435226: 0.126920093865\n",
      "3092863895: 0.126497493583\n",
      "----------------auths-------------------------\n",
      "3042570996: 1.0\n",
      "3065514742: 0.905608035937\n",
      "1638625987: 0.81511290402\n",
      "3077733683: 0.526217876188\n",
      "3039321886: 0.411904770114\n",
      "3077695572: 0.223794722843\n",
      "3019659587: 0.207900590021\n",
      "1358345766: 0.179998267529\n",
      "3061155846: 0.172568907917\n",
      "3092580049: 0.172006968736\n",
      "571198546: 0.149751447319\n",
      "3068694151: 0.137856674825\n",
      "3058933933: 0.131564390769\n",
      "3154266823: 0.128606462351\n",
      "3126638673: 0.115776140619\n",
      "3082049188: 0.113969631912\n",
      "610166901: 0.106718707085\n",
      "3083157411: 0.106062127502\n",
      "3190712044: 0.0943517687822\n",
      "3086054424: 0.0851867946656\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "from operator import itemgetter, attrgetter\n",
    "hubs_in = np.transpose(np.ones(matrix.shape[0]))\n",
    "auths_in = np.transpose(np.ones(matrix.shape[1]))\n",
    "\n",
    "iterations = 100\n",
    "\n",
    "auths_f = np.array\n",
    "hubs_f = np.array\n",
    "for i in range(iterations):\n",
    "    auths_f = sparse.csr_matrix.dot(sparse.csr_matrix.transpose(matrix).tocsr(),hubs_in)\n",
    "    hubs_f = sparse.csr_matrix.dot(matrix,auths_f)\n",
    "    auths_in = auths_f/max(auths_f)\n",
    "    hubs_in = hubs_f/max(hubs_f)\n",
    "    \n",
    "auths_f = auths_f/max(auths_f)\n",
    "hubs_f = hubs_f/max(hubs_f)\n",
    "\n",
    "hub_score = dict()\n",
    "auth_score = dict()\n",
    "\n",
    "for key, value in names.iteritems():\n",
    "        hub_score[key] = hubs_f[value]\n",
    "        auth_score[key] = auths_f[value]\n",
    "\n",
    "print \"######### after\",iterations,\" iterations ###############\" \n",
    "\n",
    "print \"----------------hubs-------------------------\"\n",
    "\n",
    "for key, value in sorted(hub_score.iteritems(), key=lambda (k,v): (v,k),reverse = True)[0:20]:\n",
    "    print \"%s: %s\" % (key, value)\n",
    "\n",
    "print \"----------------auths-------------------------\"\n",
    "\n",
    "for key, value in sorted(auth_score.iteritems(), key=lambda (k,v): (v,k),reverse = True)[0:20]:\n",
    "    print \"%s: %s\" % (key, value)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
